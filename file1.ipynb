{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "import time\n",
    "import ijson\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to extract data with locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63201091459\n",
      "166476331\n"
     ]
    }
   ],
   "source": [
    "# Recording only the tweets where places are given.\n",
    "f=open('mnt/ext100/twitter-huge.json', encoding='utf-8')\n",
    "g=open('twitter-place-data.json','w',encoding='utf-8')\n",
    "g.write('[\\n')\n",
    "f.seek(0,os.SEEK_END)\n",
    "size=f.tell()\n",
    "print(size)\n",
    "f.seek(0)\n",
    "metadata=f.readline()\n",
    "nrows=int(metadata.split(':')[1].split(',')[0]) # number of rows given in the file are wrong.\n",
    "print(nrows)\n",
    "nrows=nrows//10000\n",
    "# nrows=500\n",
    "try:\n",
    "    for i in range(nrows):\n",
    "        data=f.readline()\n",
    "        try:\n",
    "            data=json.loads(data[:-2])\n",
    "        except:\n",
    "            print(f'Error in row and location:{i} {f.tell()}')\n",
    "            if f.tell()>=size:\n",
    "                break\n",
    "        # print(data['doc'].keys())\n",
    "        else:\n",
    "            if 'includes' in data['doc'].keys():\n",
    "                last=data\n",
    "                # pass\n",
    "                # print(data)\n",
    "                g.write(json.dumps(data)+',\\n')\n",
    "    # for key,value in data.items():\n",
    "    #     print(key, value)\n",
    "except:\n",
    "    print(f'File at location {f.tell()}')\n",
    "g.write(json.dumps(last)+'\\n')\n",
    "g.write(']')\n",
    "g.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code saves tweets with covid in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This row can't be converted: [\n",
      "\n",
      "This row can't be converted: {\"id\":\"1557503993508950016\",\"key\":[2022,8,10,\"988404415789846530\",\"2762475846\",\"1557503993508950016\"],\"value\":{\"tags\":\"\",\"tokens\":\"\"},\"doc\":{\"_id\":\"1557503993508950016\",\"_rev\":\"1-abe35fd2ab64f7349e20324be877be62\",\"data\":{\"author_id\":\"2762475846\",\"conversation_id\":\"988404415789846530\",\"created_at\":\"2022-08-10T23:07:43.000Z\",\"entities\":{\"mentions\":[{\"start\":0,\"end\":15,\"username\":\"BunburyWeather\",\"id\":\"2789736120\"},{\"start\":16,\"end\":27,\"username\":\"Sparrow_65\",\"id\":\"125515218\"},{\"start\":28,\"end\":39,\"username\":\"weather_wa\",\"id\":\"986092014\"},{\"start\":40,\"end\":47,\"username\":\"baxlex\",\"id\":\"179511988\"},{\"start\":48,\"end\":61,\"username\":\"perthovalman\",\"id\":\"42854780\"},{\"start\":62,\"end\":74,\"username\":\"ManjitK6987\",\"id\":\"775918317764644864\"},{\"start\":75,\"end\":90,\"username\":\"ImTheOnlyAstro\",\"id\":\"500446308\"},{\"start\":91,\"end\":99,\"username\":\"RKMac65\",\"id\":\"461533861\"},{\"start\":100,\"end\":114,\"username\":\"TrixieBelden_\",\"id\":\"1224956765474709504\"},{\"start\":115,\"end\":122,\"username\":\"drstip\",\"id\":\"258298063\"},{\"start\":123,\"end\":134,\"username\":\"2017Ferret\",\"id\":\"857774997724475392\"},{\"start\":135,\"end\":142,\"username\":\"paulmp\",\"id\":\"22744846\"},{\"start\":143,\"end\":159,\"username\":\"Richard_Kreider\",\"id\":\"1674489318\"},{\"start\":160,\"end\":176,\"username\":\"sivideoaviation\",\"id\":\"948503715937361920\"},{\"start\":177,\"end\":189,\"username\":\"Barnsy_Lisa\",\"id\":\"29326170\"},{\"start\":190,\"end\":202,\"username\":\"BigV2011WCE\",\"id\":\"191761621\"},{\"start\":203,\"end\":215,\"username\":\"wiccewicker\",\"id\":\"827791722209898496\"},{\"start\":216,\"end\":226,\"username\":\"Rob_lebob\",\"id\":\"1211227922075246594\"},{\"start\":227,\"end\":235,\"username\":\"TheWAWG\",\"id\":\"176041453\"},{\"start\":236,\"end\":250,\"username\":\"aussie_robbob\",\"id\":\"4374920592\"},{\"start\":251,\"end\":263,\"username\":\"WendyBirdOZ\",\"id\":\"2195966832\"},{\"start\":264,\"end\":275,\"username\":\"N8aviation\",\"id\":\"1218828602810105857\"},{\"start\":276,\"end\":285,\"username\":\"perthobs\",\"id\":\"3229987878\"}]},\"geo\":{\"place_id\":\"0118c71c0ed41109\"},\"lang\":\"und\",\"public_metrics\":{\"retweet_count\":0,\"reply_count\":0,\"like_count\":0,\"quote_count\":0},\"text\":\"@BunburyWeather @Sparrow_65 @weather_wa @baxlex @perthovalman @ManjitK6987 @ImTheOnlyAstro @RKMac65 @TrixieBelden_ @drstip @2017Ferret @paulmp @Richard_Kreider @sivideoaviation @Barnsy_Lisa @BigV2011WCE @wiccewicker @Rob_lebob @TheWAWG @aussie_robbob @WendyBirdOZ @N8aviation @perthobs \\ud83d\\udc4d\\ud83d\\udc4d\\ud83d\\ude03\\ud83d\\ude03\",\"sentiment\":0},\"includes\":{\"places\":[{\"full_name\":\"Perth, Western Australia\",\"geo\":{\"type\":\"Feature\",\"bbox\":[115.617614368,-32.675715325,116.239023008,-31.6244855145],\"properties\":{}},\"id\":\"0118c71c0ed41109\"}]},\"matching_rules\":[{\"id\":\"1557388137877635072\",\"tag\":\"\"}]}}\n",
      "\n",
      "This row can't be converted: ]\n"
     ]
    }
   ],
   "source": [
    "## Adding JSON database to couchDB\n",
    "# Number of tweets in couchDB file=3236320\n",
    "import couchdb\n",
    "import json\n",
    "keyterms=['covid', 'covid-19', 'coronavirus', 'covid-vaccine', 'vaccines', 'vaccine']\n",
    "dbname='tweetscovid'\n",
    "dbaddress='http://admin:Royai99@127.0.0.1:5984/' #change the address to the couchdb server\n",
    "couch = couchdb.Server(dbaddress)\n",
    "if dbname in couch:\n",
    "    del couch[dbname]\n",
    "    db=couch.create(dbname)\n",
    "else:\n",
    "    db=couch.create(dbname)\n",
    "filename='twitter-place-data.json'\n",
    "filename='C:/Users/Kunal Patel/D folder/_Master_data_science/Cluster and Cloud Computing/twitter-place-data.json'\n",
    "jsonfile=open(filename,'r', encoding='utf-8')\n",
    "i=-1\n",
    "for row in jsonfile:\n",
    "    # i+=1\n",
    "    # if(i%10==0):\n",
    "        # print(row[:-2])\n",
    "        try:\n",
    "            data = json.loads(row[:-2])\n",
    "        except:\n",
    "            print(f'This row can\\'t be converted: {row}')\n",
    "        else:\n",
    "            try:\n",
    "                place=data['doc']['includes']['places'][0]\n",
    "            except:\n",
    "                place={'full_name':'Australia'}\n",
    "            time=data['doc']['data']['created_at']\n",
    "            text=data['doc']['data']['text']\n",
    "            sentiment=data['doc']['data']['sentiment']\n",
    "            # tags=data['doc']['data']['entities']['mentions']\n",
    "            tokens=data['value']['tokens']\n",
    "            tokenlist=tokens.split(\"|\")\n",
    "            for word in tokenlist:\n",
    "                if word.lower() in keyterms:\n",
    "                    db_entry={\n",
    "                        'place':place,\n",
    "                        'time':time,\n",
    "                        'text':text,\n",
    "                        'sentiment':sentiment,\n",
    "                        'tokens':tokens\n",
    "                    }\n",
    "                    db.save(db_entry)\n",
    "                    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to save tweets with ukraine or war in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This row can't be converted: [\n",
      "\n",
      "This row can't be converted: {\"id\":\"1557503993508950016\",\"key\":[2022,8,10,\"988404415789846530\",\"2762475846\",\"1557503993508950016\"],\"value\":{\"tags\":\"\",\"tokens\":\"\"},\"doc\":{\"_id\":\"1557503993508950016\",\"_rev\":\"1-abe35fd2ab64f7349e20324be877be62\",\"data\":{\"author_id\":\"2762475846\",\"conversation_id\":\"988404415789846530\",\"created_at\":\"2022-08-10T23:07:43.000Z\",\"entities\":{\"mentions\":[{\"start\":0,\"end\":15,\"username\":\"BunburyWeather\",\"id\":\"2789736120\"},{\"start\":16,\"end\":27,\"username\":\"Sparrow_65\",\"id\":\"125515218\"},{\"start\":28,\"end\":39,\"username\":\"weather_wa\",\"id\":\"986092014\"},{\"start\":40,\"end\":47,\"username\":\"baxlex\",\"id\":\"179511988\"},{\"start\":48,\"end\":61,\"username\":\"perthovalman\",\"id\":\"42854780\"},{\"start\":62,\"end\":74,\"username\":\"ManjitK6987\",\"id\":\"775918317764644864\"},{\"start\":75,\"end\":90,\"username\":\"ImTheOnlyAstro\",\"id\":\"500446308\"},{\"start\":91,\"end\":99,\"username\":\"RKMac65\",\"id\":\"461533861\"},{\"start\":100,\"end\":114,\"username\":\"TrixieBelden_\",\"id\":\"1224956765474709504\"},{\"start\":115,\"end\":122,\"username\":\"drstip\",\"id\":\"258298063\"},{\"start\":123,\"end\":134,\"username\":\"2017Ferret\",\"id\":\"857774997724475392\"},{\"start\":135,\"end\":142,\"username\":\"paulmp\",\"id\":\"22744846\"},{\"start\":143,\"end\":159,\"username\":\"Richard_Kreider\",\"id\":\"1674489318\"},{\"start\":160,\"end\":176,\"username\":\"sivideoaviation\",\"id\":\"948503715937361920\"},{\"start\":177,\"end\":189,\"username\":\"Barnsy_Lisa\",\"id\":\"29326170\"},{\"start\":190,\"end\":202,\"username\":\"BigV2011WCE\",\"id\":\"191761621\"},{\"start\":203,\"end\":215,\"username\":\"wiccewicker\",\"id\":\"827791722209898496\"},{\"start\":216,\"end\":226,\"username\":\"Rob_lebob\",\"id\":\"1211227922075246594\"},{\"start\":227,\"end\":235,\"username\":\"TheWAWG\",\"id\":\"176041453\"},{\"start\":236,\"end\":250,\"username\":\"aussie_robbob\",\"id\":\"4374920592\"},{\"start\":251,\"end\":263,\"username\":\"WendyBirdOZ\",\"id\":\"2195966832\"},{\"start\":264,\"end\":275,\"username\":\"N8aviation\",\"id\":\"1218828602810105857\"},{\"start\":276,\"end\":285,\"username\":\"perthobs\",\"id\":\"3229987878\"}]},\"geo\":{\"place_id\":\"0118c71c0ed41109\"},\"lang\":\"und\",\"public_metrics\":{\"retweet_count\":0,\"reply_count\":0,\"like_count\":0,\"quote_count\":0},\"text\":\"@BunburyWeather @Sparrow_65 @weather_wa @baxlex @perthovalman @ManjitK6987 @ImTheOnlyAstro @RKMac65 @TrixieBelden_ @drstip @2017Ferret @paulmp @Richard_Kreider @sivideoaviation @Barnsy_Lisa @BigV2011WCE @wiccewicker @Rob_lebob @TheWAWG @aussie_robbob @WendyBirdOZ @N8aviation @perthobs \\ud83d\\udc4d\\ud83d\\udc4d\\ud83d\\ude03\\ud83d\\ude03\",\"sentiment\":0},\"includes\":{\"places\":[{\"full_name\":\"Perth, Western Australia\",\"geo\":{\"type\":\"Feature\",\"bbox\":[115.617614368,-32.675715325,116.239023008,-31.6244855145],\"properties\":{}},\"id\":\"0118c71c0ed41109\"}]},\"matching_rules\":[{\"id\":\"1557388137877635072\",\"tag\":\"\"}]}}\n",
      "\n",
      "This row can't be converted: ]\n"
     ]
    }
   ],
   "source": [
    "import couchdb\n",
    "import json\n",
    "dbname='tweetsukraine'\n",
    "dbaddress='http://admin:Royai99@127.0.0.1:5984/'\n",
    "keyterms=['ukraine','war']\n",
    "couch = couchdb.Server(dbaddress)\n",
    "if dbname in couch:\n",
    "    del couch[dbname]\n",
    "    db=couch.create(dbname)\n",
    "else:\n",
    "    db=couch.create(dbname)\n",
    "filename='twitter-place-data.json'\n",
    "filename='C:/Users/Kunal Patel/D folder/_Master_data_science/Cluster and Cloud Computing/twitter-place-data.json'\n",
    "jsonfile=open(filename,'r', encoding='utf-8')\n",
    "# size=jsonfile.seek(0,os.SEEK_END)\n",
    "# jsonfile.seek(size-100000)\n",
    "# data=jsonfile.read()\n",
    "# print(data)\n",
    "i=-1\n",
    "for row in jsonfile:\n",
    "    # i+=1\n",
    "    # if(i%10==0):\n",
    "        # print(row[:-2])\n",
    "        try:\n",
    "            data = json.loads(row[:-2])\n",
    "            \n",
    "        except:\n",
    "            print(f'This row can\\'t be converted: {row}')\n",
    "        else:\n",
    "            try:\n",
    "                place=data['doc']['includes']['places'][0]\n",
    "            except:\n",
    "                place={'full_name':'Australia'}\n",
    "            time=data['doc']['data']['created_at']\n",
    "            text=data['doc']['data']['text']\n",
    "            sentiment=data['doc']['data']['sentiment']\n",
    "            # tags=data['doc']['data']['entities']['mentions']\n",
    "            tokens=data['value']['tokens']\n",
    "            tokenlist=tokens.split(\"|\")\n",
    "            \n",
    "            for word in tokenlist:\n",
    "                if word.lower() in keyterms:\n",
    "                    db_entry={\n",
    "                        'place':place,\n",
    "                        'time':time,\n",
    "                        'text':text,\n",
    "                        'sentiment':sentiment,\n",
    "                        'tokens':tokens\n",
    "                    }\n",
    "                    db.save(db_entry)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database exists\n",
      "3236320\n"
     ]
    }
   ],
   "source": [
    "import couchdb\n",
    "import json\n",
    "dbname='tweets'\n",
    "dbaddress='http://admin:Royai99@127.0.0.1:5984/'\n",
    "couch = couchdb.Server(dbaddress)\n",
    "if dbname in couch:\n",
    "    db = couch[dbname]\n",
    "    print('Database exists')\n",
    "else:\n",
    "    db=couch.create(dbname)\n",
    "    print('No such database')\n",
    "print(db.info()['doc_count'])\n",
    "for item in db.view('_design/text_extract/_view/new-view'):\n",
    "    print(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet to get "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toot processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['account', 'card', 'content', 'created_at', 'edited_at', 'emojis', 'favourites_count', 'filtered', 'id', 'in_reply_to_account_id', 'in_reply_to_id', 'language', 'media_attachments', 'mentions', 'poll', 'reblog', 'reblogs_count', 'replies_count', 'sensitive', 'spoiler_text', 'tags', 'uri', 'url', 'visibility'])\n"
     ]
    }
   ],
   "source": [
    "## Toot processing\n",
    "import ijson\n",
    "import json\n",
    "import html2text\n",
    "import re\n",
    "f=open('onetoot.json','r',encoding='utf-8')\n",
    "x=json.load(f)\n",
    "print(x.keys())\n",
    "date=x['created_at']\n",
    "text=x['content']\n",
    "\n",
    "\n",
    "h = html2text.HTML2Text()\n",
    "h.ignore_links = True\n",
    "text=h.handle(text).strip(\"\\n \")\n",
    "# print(date, text)\n",
    "\n",
    "g=open('toot_sample.txt','r',encoding='utf-8')\n",
    "h=open('toot-fixed.txt','w',encoding='utf-8')\n",
    "for row in g:\n",
    "    # print(row)\n",
    "    if re.match(r\"}{\",row):\n",
    "        h.write('},\\n')\n",
    "        h.write('{')\n",
    "        pass\n",
    "    else:\n",
    "        h.write(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
